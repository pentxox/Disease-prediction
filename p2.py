# -*- coding: utf-8 -*-
"""p2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10Ew5_kPQUh_jk_9xj2tD8oUcGqhMZbs2
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import shap
from lime.lime_tabular import LimeTabularExplainer
import warnings
warnings.filterwarnings('ignore')

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.ensemble import GradientBoostingClassifier

df=pd.read_csv('../dataset/symbipredict_2022.csv')
print(df.head())

print(df.shape)

print(df['prognosis'].unique())

print(df['prognosis'].nunique())

print(df.isna().sum())

print(df.prognosis.value_counts())

prognosis_counts = df['prognosis'].value_counts()
# Plotting the pie chart
plt.figure(figsize=(8, 8))
prognosis_counts.plot.pie(autopct='%1.1f%%', startangle=90, cmap='viridis', ylabel='')
plt.title('Prognosis Distribution', fontsize=16)
plt.show()

df.columns

plt.figure(figsize=(10, 6))
sns.countplot(data=df, x='prognosis', palette='viridis')
plt.title('Count Plot of Prognosis', fontsize=16)
plt.xlabel('Prognosis', fontsize=14)
plt.ylabel('Count', fontsize=14)
plt.xticks(rotation=90, fontsize=12)
plt.show()

le = LabelEncoder()
df['prognosis'] = le.fit_transform(df['prognosis'])

label_mapping = dict(zip(le.classes_, le.transform(le.classes_)))
print("Label Mapping:", label_mapping)

df.head()

print(df.corr()['prognosis'])

pd.set_option('display.max_rows', None)   # Show all rows
pd.set_option('display.max_columns', None)  # Show all columns

# Display the correlation of the 'prognosis' column
print(df.corr()['prognosis'])

features_to_keep = [
    'chills', 'acidity', 'knee_pain', 'vomiting', 'diarrhoea',
    'belly_pain', 'fatigue', 'sweating', 'indigestion', 'headache',
    'blood_in_sputum', 'fast_heart_rate', 'cramps', 'bruising', 'nausea',
    'spinning_movements', 'swollen_legs', 'skin_peeling', 'unsteadiness', 'internal_itching','prognosis'
]


df_filtered = df[features_to_keep]

# Display the shape and the first few rows of the filtered DataFrame
print("Filtered DataFrame shape:", df_filtered.shape)
print(df_filtered.head())

for i in features_to_keep:
    print(df[i].unique())
    print('*'*50)

print(df_filtered.corr() ['prognosis'])

plt.figure(figsize=(12, 10))
sns.heatmap(df_filtered.corr(), annot=True, fmt=".2f", cmap="coolwarm", cbar=True, linewidths=0.5)
plt.title('Data Correlations', fontsize=16)
plt.show()

# df_filtered.to_csv('../dataset/cleaned.csv')

X=df_filtered.drop(['prognosis'],axis=1)
y=df_filtered['prognosis']

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)

rf= RandomForestClassifier(max_depth=5)
rf.fit(X_train, y_train)

explainer=shap.TreeExplainer(rf)
shap_val=explainer.shap_values(X_test)

shap.summary_plot(shap_val,X_test)

y_train_pred = rf.predict(X_train)
y_test_pred = rf.predict(X_test)

from sklearn.metrics import accuracy_score, classification_report
train_accuracy = accuracy_score(y_train, y_train_pred)
test_accuracy = accuracy_score(y_test, y_test_pred)

print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

# Classification report for more detailed performance metrics
print("\nClassification Report (Test Data Random Forest):")
print(classification_report(y_test, y_test_pred))

import joblib

# Save the trained model to a file
model_filename = 'random_forest_model.pkl'
joblib.dump(rf, model_filename)
print(f"Model saved to {model_filename}")

gbc = GradientBoostingClassifier(random_state=42)
gbc.fit(X_train, y_train)

gbc_y_train_pred = gbc.predict(X_train)
gbc_y_test_pred = gbc.predict(X_test)

train_accuracy = accuracy_score(y_train, gbc_y_train_pred)
test_accuracy = accuracy_score(y_test, gbc_y_test_pred)

print(f"Training Accuracy: {train_accuracy:.2f}")
print(f"Test Accuracy: {test_accuracy:.2f}")

gbc_model_filename = 'gradient_boosting_model.pkl'
joblib.dump(gbc, gbc_model_filename)
print(f"Gradient Boosting model saved to {gbc_model_filename}")

loaded_gbc_model = joblib.load(gbc_model_filename)

custom_input = np.array([[1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1]])

# Make a prediction
prediction = loaded_gbc_model.predict(custom_input)
predicted_proba = loaded_gbc_model.predict_proba(custom_input)

print(prediction)

#  Display the prediction and probabilities
print(f"Predicted Class: {prediction[0]}")
print(f"Prediction Probabilities: {predicted_proba}")

df=pd.read_csv('../dataset/cleaned.csv')
df.head()

df = df.drop(['Unnamed: 0'],axis=1)

# df.to_csv('../dataset/cleaned.csv',index=False)

